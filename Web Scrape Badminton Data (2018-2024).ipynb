{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ad7344-93bf-4c24-98db-bfcde366c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc9cf62-81dd-4edb-836d-be6e608be903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(html, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(html)\n",
    "        \n",
    "def open_html(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return f.read() \n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\"\n",
    "    }\n",
    "def save_scrapes (urls, file_names):\n",
    "    for page, file_name in zip(urls, file_names):\n",
    "        r = requests.get(page,headers=headers)\n",
    "        save_html(r.content, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c2edbf-2ac6-491e-b2b7-bfead68084ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only extract All England, Indonesia Open, China Open, and Malaysia Open\n",
    "open_keywords = [\"all-england-open\", \"malaysia-open\", \"indonesia-open\", \"victor-china-open\"]\n",
    "tour_urls = [\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2018&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2019&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2020&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2021&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2022&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2023&rstate=completed\",\n",
    "    \"https://bwfworldtour.bwfbadminton.com/calendar/?cyear=2024&rstate=completed\"\n",
    "]\n",
    "tour_files = ['tour_2018.txt', 'tour_2019.txt', 'tour_2020.txt',\n",
    "              'tour_2021.txt','tour_2022.txt', 'tour_2023.txt', 'tour_2024.txt']\n",
    "#save_scrapes(tour_urls, tour_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9d66da-2202-4692-854b-936dcdc38916",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_keywords = [\"all-england-open\", \"malaysia-open\", \"indonesia-open\", \"victor-china-open\"]\n",
    "#Exclude cancelled opens and non super-1000 malaysia opens\n",
    "exclude_opens = ['malaysia-open-2018',\n",
    "                'malaysia-open-2019',\n",
    "                'malaysia-open-2020',\n",
    "                'malaysia-open-2021',\n",
    "                'malaysia-open-2022',\n",
    "                'china-open-2020',\n",
    "                'china-open-2021',\n",
    "                'china-open-2022',\n",
    "                'indonesia-open-2020']\n",
    "tour_urls = []\n",
    "for file in tour_files:\n",
    "    r = open_html(file)\n",
    "    soup = bs(r, 'html.parser')\n",
    "    game_list = soup.select('div.page-content')\n",
    "    games = game_list[0].select('div.item-results')\n",
    "    for game in games:\n",
    "        links = game.select('div.tblResultLanding a')\n",
    "        for link in links:\n",
    "            href = link.get('href', '')\n",
    "            if any(keyword in href for keyword in game_keywords):\n",
    "                tour_urls.append(href)\n",
    "\n",
    "#Filter the urls\n",
    "filtered_urls = [url for url in tour_urls if not any(keyword in url for keyword in exclude_opens)]\n",
    "filtered_urls = [url + '/results/podium/' for url in filtered_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c03ab24-4f47-45dc-b163-dc37cd53933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_url = []\n",
    "for url in filtered_urls:\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = bs(r.content, 'html.parser')\n",
    "    match_days = soup.select('#ajaxTabsResults li')[1:-1]\n",
    "    for day in match_days:\n",
    "        a_tag = day.find('a')\n",
    "        if a_tag and 'href' in a_tag.attrs:\n",
    "            match_url = a_tag['href']\n",
    "            matches_url.append(match_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9069d876-7b2c-4799-a4cf-b7fbd9d71373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the data dicts\n",
    "data = {\n",
    "    \"Tournament Name\": [],\n",
    "    \"Tournament Date\": [],\n",
    "    \"Tournament Country\": [],\n",
    "    \"Discipline\": [],\n",
    "    \"Number of Sets Played\": [],\n",
    "    \"Retired\": [],  # 1 if true, 0 if false\n",
    "    \"Match Duration\": [],\n",
    "    \"Team 1 Nationalities\": [],\n",
    "    \"Team 2 Nationalities\": [],\n",
    "    \"Team 1 Name(s)\": [],\n",
    "    \"Team 1 Seed\": [],\n",
    "    \"Team 2 Name(s)\": [],\n",
    "    \"Team 2 Seed\": [],\n",
    "    \"Points Set 1 Team 1\": [],\n",
    "    \"Points Set 1 Team 2\": [],\n",
    "    \"Points Set 2 Team 1\": [],\n",
    "    \"Points Set 2 Team 2\": [],\n",
    "    \"Points Set 3 Team 1\": [],  # empty if not applicable\n",
    "    \"Points Set 3 Team 2\": [], \n",
    "    \"Total Points Team 1\": [],\n",
    "    \"Total Points Team 2\": [],\n",
    "    \"Sets Won Team 1\": [],\n",
    "    \"Sets Won Team 2\": [],\n",
    "    \"Total Game Points Team 1\": [],\n",
    "    \"Total Game Points Team 2\": [],\n",
    "    \"Most Consecutive Points Team 1\": [],\n",
    "    \"Most Consecutive Points Team 2\": [],\n",
    "    \"Team 1 Head to Head Analysis\": [],\n",
    "    \"Team 2 Head to Head Analysis\": [],\n",
    "    \"Match Winner\": []  # 1 if Team 1 wins, 2 if Team 2 wins\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b7bd47-49ec-4065-8119-7f7ea4a8eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_filename = []\n",
    "for url in matches_url:\n",
    "    # Split the URL to extract relevant parts\n",
    "    url_parts = url.split('/')\n",
    "    tournament_name = url_parts[5].replace('-', '_')\n",
    "    match_date = url_parts[-1]\n",
    "    # Generate the file name\n",
    "    file_name = f\"{tournament_name}_{match_date}_match.txt\"\n",
    "    matches_filename.append(file_name)\n",
    "save_scrapes(matches_url, matches_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d4cbd2a-8c55-4403-ac10-3572e788fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tournament function\n",
    "def extract_tournament_info(file_name):\n",
    "    parts = file_name.replace(\".txt\", \"\").split(\"_\")\n",
    "    tournament_name = \"_\".join(parts[:-2])\n",
    "    tournament_name = tournament_name[:-5]\n",
    "    tournament_date = parts[-2]\n",
    "    country_keywords = ['indonesia', 'china', 'england', 'malaysia']\n",
    "    for country in country_keywords:\n",
    "        if country in file_name.lower():\n",
    "            tournament_country = country.capitalize()\n",
    "            break  # Stop once the country is found\n",
    "    return tournament_name, tournament_date, tournament_country\n",
    "\n",
    "# Name and seed extraction function\n",
    "def extract_name_and_seed(player_info):\n",
    "    # Assuming format: 'Name [Seed]'\n",
    "    if '[' in player_info and ']' in player_info:\n",
    "        name, seed = player_info.split('[', 1)\n",
    "        seed = seed.split(']', 1)[0]\n",
    "        return name.strip(), seed.strip()\n",
    "    else:\n",
    "        return player_info.strip(), None\n",
    "\n",
    "# Extract nationality from png\n",
    "def extract_nationality(flag_url):\n",
    "    # Extracts the country name from the URL (e.g., 'bulgaria.png')\n",
    "    return flag_url.split('/')[-1].replace('.png', '')\n",
    "\n",
    "# Match duration extraction\n",
    "def extract_duration(duration_str):\n",
    " # Time format where '1.07' = 1 hour 7 minutes\n",
    "    parts = duration_str.split(':')\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "def determine_match_winner(sets_won_team_1, sets_won_team_2):\n",
    "    team1_won = False\n",
    "    team2_won = False\n",
    "    # Determine match winner\n",
    "    if sets_won_team_1 > sets_won_team_2:\n",
    "        match_winner = 1  # Team 1 wins\n",
    "    elif sets_won_team_1 < sets_won_team_:\n",
    "        match_winner = 2  # Team 2 wins\n",
    "    else:\n",
    "        match_winner = 0  # Draw\n",
    "    \n",
    "    return match_winner\n",
    "\n",
    "def process_score_stats(scores):\n",
    "    # Initialize variables\n",
    "    team1_points = []\n",
    "    team2_points = []\n",
    "    \n",
    "    # Assign points alternately to Team 1 and Team 2\n",
    "    for index, score in enumerate(scores):\n",
    "        if index % 2 == 0:\n",
    "            team1_points.append(score)\n",
    "        else:\n",
    "            team2_points.append(score)\n",
    "    \n",
    "    # Calculate total points for each team\n",
    "    total_points_team_1 = int(sum(team1_points))\n",
    "    total_points_team_2 = int(sum(team2_points))\n",
    "    \n",
    "    # Determine the number of sets won by each team\n",
    "    sets_won_team_1 = int(sum(1 for i in range(len(team1_points)) if team1_points[i] > team2_points[i]))\n",
    "    sets_won_team_2 = int(sum(1 for i in range(len(team2_points)) if team2_points[i] > team1_points[i]))\n",
    "    return total_points_team_1, total_points_team_2, sets_won_team_1, sets_won_team_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9022bf4f-6bae-492b-be64-77af6a91ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_match(file, headers, doubles_data):\n",
    "    #Open saved web scrape \n",
    "    r = open_html(file)\n",
    "    \n",
    "    #Extract tournament info from file name \n",
    "    soup = bs(r, 'html.parser')\n",
    "    tournament_name, tournament_date, tournament_country = extract_tournament_info(file)\n",
    "    ul_elements = soup.select('ul.list-sort-time')\n",
    "    for ul in ul_elements:\n",
    "        li_elements = ul.find_all('li')\n",
    "        for li in li_elements:\n",
    "            if 'location-name' not in li.get('class', []) and 'stats' not in li.get('class', []):\n",
    "                # Extract Game and Player Information\n",
    "                discipline = li.select_one('div.round').text.strip()\n",
    "                scores = li.select('div.player-score-wrap > div.score')\n",
    "                set_scores = [score.text.strip().split(',') for score in scores]\n",
    "                set_scores = [score for sublist in set_scores for score in sublist]\n",
    "                \n",
    "                player_info = li.select('div.player-wrap > div.team-details-wrap')\n",
    "                if 'Walkover' not in set_scores: #skip over walkover games\n",
    "                # Match Statistics and Player Information\n",
    "                    match_duration = extract_duration(li.select_one('div.timer1 > span').text)\n",
    "                    team_1_nationality = extract_nationality(player_info[0].select_one('div.flag > img')['src'])\n",
    "                    team_2_nationality = extract_nationality(player_info[1].select_one('div.flag > img')['src'])\n",
    "                    points_set_1_team_1, points_set_1_team_2 = None, None\n",
    "                    points_set_2_team_1, points_set_2_team_2 = None, None\n",
    "                    points_set_3_team_1, points_set_3_team_2 = None, None\n",
    "                    retired = False\n",
    "                    if any('retired' in score.lower() for score in set_scores):\n",
    "                        retired = True\n",
    "                        set_scores = [score for score in set_scores if 'retired' not in score.lower()]\n",
    "                    \n",
    "                    set_scores = [score.split('-') for score in set_scores]\n",
    "                    set_scores = [score for sublist in set_scores for score in sublist]\n",
    "                    set_scores = [int(score) for score in set_scores]\n",
    "                    if len(set_scores) >= 2:\n",
    "                        points_set_1_team_1, points_set_1_team_2 = set_scores[0], set_scores[1]\n",
    "                    if len(set_scores) >= 4:\n",
    "                        points_set_2_team_1, points_set_2_team_2 = set_scores[2], set_scores[3]\n",
    "                    if len(set_scores) >= 6:\n",
    "                        points_set_3_team_1, points_set_3_team_2 = set_scores[4], set_scores[5]\n",
    "        \n",
    "                    #Calculate score game stats:\n",
    "                    total_points_team_1, total_points_team_2, sets_won_team_1, sets_won_team_2 = process_score_stats(set_scores)\n",
    "                    match_winner = determine_match_winner(sets_won_team_1, sets_won_team_2)\n",
    "                    match_link_tag = li.select_one('a#match-link')\n",
    "                    href = match_link_tag.get('href')\n",
    "                    modified_href = href.replace('stab=result', 'stab=match')\n",
    "            \n",
    "                    # Find corresponding stats div for each match \n",
    "                    match_classes = [cls for cls in li.get('class', []) if cls.startswith('match-')]\n",
    "                    table_r = requests.get(modified_href, headers=headers)\n",
    "                    table_soup = bs(table_r.content, 'html.parser')\n",
    "                    match_number = match_classes[0].split('-')[-1] #extract match number to get corresponding stats div\n",
    "                    stats_div = table_soup.select_one(f'li.stats.stats-{match_number}') \n",
    "            \n",
    "                    # Extracting the game points and consecutive points from stats table\n",
    "                    table = stats_div.find('table')\n",
    "                    rows = table.find_all('tr')\n",
    "                    most_consecutive_points_row = rows[0]\n",
    "                    t1_most_consecutive_text = most_consecutive_points_row.find('td', class_='t1').get_text(strip=True)\n",
    "                    t2_most_consecutive_text = most_consecutive_points_row.find('td', class_='t2').get_text(strip=True)\n",
    "                    \n",
    "                    t1_most_consecutive = int(t1_most_consecutive_text) if t1_most_consecutive_text.isdigit() else 0\n",
    "                    t2_most_consecutive = int(t2_most_consecutive_text) if t2_most_consecutive_text.isdigit() else 0\n",
    "                    \n",
    "                    # Extract and handle 'game points'\n",
    "                    game_points_row = rows[1]\n",
    "                    t1_game_points_text = game_points_row.find('td', class_='t1').get_text(strip=True)\n",
    "                    t2_game_points_text = game_points_row.find('td', class_='t2').get_text(strip=True)\n",
    "                    \n",
    "                    t1_game_points = int(t1_game_points_text) if t1_game_points_text.isdigit() else 0\n",
    "                    t2_game_points = int(t2_game_points_text) if t2_game_points_text.isdigit() else 0\n",
    "                    # Extracting the h2h analysis\n",
    "                    modified_href = href.replace('stab=result', 'stab=h2h')\n",
    "                    h2h_r = requests.get(modified_href, headers=headers)\n",
    "                    h2h_soup = bs(h2h_r.content, 'html.parser')\n",
    "                    stats_div_h2h = h2h_soup.select_one(f'li.stats.stats-{match_number}')\n",
    "                    t1_h2h= int(stats_div_h2h.select_one('div.cifr1').get_text(strip=True))\n",
    "                    t2_h2h= int(stats_div_h2h.select_one('div.cifr2').get_text(strip=True))\n",
    "            \n",
    "                \n",
    "                    if discipline in ['MS', 'WS']:  # Singles Match\n",
    "                        player_1_info = player_info[0].select_one('div.player1-wrap').text.strip()\n",
    "                        player_2_info = player_info[1].select_one('div.player3-wrap').text.strip()\n",
    "                        \n",
    "                        team_1_name, team_1_seed = extract_name_and_seed(player_1_info)\n",
    "                        team_2_name, team_2_seed = extract_name_and_seed(player_2_info)\n",
    "                    \n",
    "                    elif discipline in ['MD', 'WD', 'XD']:  # Doubles Match\n",
    "                        player_1_team_1_info = player_info[0].select_one('div.player1-wrap').text.strip()\n",
    "                        player_2_team_1_info = player_info[0].select_one('div.player2-wrap').text.strip()\n",
    "                        player_1_team_2_info = player_info[1].select_one('div.player3-wrap').text.strip()\n",
    "                        player_2_team_2_info = player_info[1].select_one('div.player4-wrap').text.strip()\n",
    "                        \n",
    "                        player_1_team_1_name, team_1_seed = extract_name_and_seed(player_1_team_1_info)\n",
    "                        player_2_team_1_name, _ = extract_name_and_seed(player_2_team_1_info)  # Same seed as player 1\n",
    "                        player_1_team_2_name, team_2_seed = extract_name_and_seed(player_1_team_2_info)\n",
    "                        player_2_team_2_name, _ = extract_name_and_seed(player_2_team_2_info)\n",
    "\n",
    "                        team_1_name = f\"{player_1_team_1_name}, {player_2_team_1_name}\"\n",
    "                        team_2_name = f\"{player_1_team_2_name}, {player_2_team_2_name}\"\n",
    "                        \n",
    "                    data[\"Tournament Name\"].append(tournament_name)\n",
    "                    data[\"Tournament Date\"].append(tournament_date)\n",
    "                    data[\"Tournament Country\"].append(tournament_country)\n",
    "                    data[\"Discipline\"].append(discipline)\n",
    "                    data[\"Number of Sets Played\"].append(len(set_scores))\n",
    "                    data[\"Retired\"].append(retired)\n",
    "                    data[\"Match Duration\"].append(match_duration)\n",
    "                    data[\"Team 1 Nationalities\"].append(team_1_nationality)\n",
    "                    data[\"Team 2 Nationalities\"].append(team_2_nationality)\n",
    "                    data[\"Team 1 Name(s)\"].append(team_1_name)\n",
    "                    data[\"Team 2 Name(s)\"].append(team_2_name)\n",
    "                    data[\"Team 1 Seed\"].append(team_1_seed)\n",
    "                    data[\"Team 2 Seed\"].append(team_2_seed)\n",
    "                    data[\"Points Set 1 Team 1\"].append(points_set_1_team_1)\n",
    "                    data[\"Points Set 1 Team 2\"].append(points_set_1_team_2)\n",
    "                    data[\"Points Set 2 Team 1\"].append(points_set_2_team_1)\n",
    "                    data[\"Points Set 2 Team 2\"].append(points_set_2_team_2)\n",
    "                    data[\"Points Set 3 Team 1\"].append(points_set_3_team_1)\n",
    "                    doubles_data[\"Points Set 3 Team 2\"].append(points_set_3_team_2)\n",
    "                    data[\"Total Points Team 1\"].append(total_points_team_1)\n",
    "                    data[\"Total Points Team 2\"].append(total_points_team_2)\n",
    "                    data[\"Sets Won Team 1\"].append(sets_won_team_1)\n",
    "                    data[\"Sets Won Team 2\"].append(sets_won_team_2)\n",
    "                    data[\"Total Game Points Team 1\"].append(t1_game_points)  \n",
    "                    data[\"Total Game Points Team 2\"].append(t2_game_points)\n",
    "                    data[\"Most Consecutive Points Team 1\"].append(t1_most_consecutive)\n",
    "                    data[\"Most Consecutive Points Team 2\"].append(t2_most_consecutive)\n",
    "                    data[\"Team 1 Head to Head Analysis\"].append(t1_h2h) \n",
    "                    data[\"Team 2 Head to Head Analysis\"].append(t2_h2h)\n",
    "                    data[\"Match Winner\"].append(match_winner)\n",
    "\n",
    "def process_matches_in_parallel(matches_filename, headers):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(process_single_match, file, headers,data): file for file in matches_filename}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {futures[future]}: {e}\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c0cbe5a-fed0-49fe-9c8a-0e359bf69478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_matches_in_parallel(matches_filename, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c69c13-6a8a-4a77-8f12-742e5428b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes and fix some formatting \n",
    "\n",
    "data_df= pd.DataFrame(data)\n",
    "cap_columns = [\n",
    "    'Team 1 Name(s)', 'Team 2 Name(s)', \n",
    "    'Team 1 Nationalities', 'Team 2 Nationalities', \n",
    "    'Tournament Country', 'Tournament Name'\n",
    "]\n",
    "for col in cap_columns:\n",
    "    data_df[col] = data_df[col].str.title()\n",
    "data_df['Team 1 Nationalities'] = data_df['Team 1 Nationalities'].replace('Chn', 'China')\n",
    "data_df['Team 2 Nationalities'] = data_df['Team 2 Nationalities'].replace('Chn', 'China')\n",
    "data_df.loc[data_df['Tournament Country'] == 'England', 'Tournament Name'] = 'Yonex_All_England_Open'\n",
    "data_df['Number of Sets Played'] = data_df['Number of Sets Played'].astype(int)\n",
    "data_df['Retired'] = data_df['Retired'].astype(int)\n",
    "\n",
    "data_df['Team 1 Seed'] = pd.to_numeric(data_df['Team 1 Seed'])\n",
    "data_df['Team 2 Seed'] = pd.to_numeric(data_df['Team 2 Seed'])\n",
    "\n",
    "to_int_points = [\n",
    "    'Points Set 1 Team 1', 'Points Set 1 Team 2',\n",
    "    'Points Set 2 Team 1', 'Points Set 2 Team 2',\n",
    "    'Points Set 3 Team 1', 'Points Set 3 Team 2'\n",
    "]\n",
    "\n",
    "for col in to_int_points:\n",
    "    data_df[col] = pd.to_numeric(data_df[col])\n",
    "\n",
    "data_df.rename(columns={'Match Duration': 'Match Duration (min)'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5cfa78-d6d6-467f-8352-5296aca9e94d",
   "metadata": {},
   "source": [
    "### Player Ranking Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a6910c-fa41-49af-9796-9051fefc6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discipline_ids = {\n",
    "    \"57\" : \"MS\",\n",
    "    \"58\" : \"WS\",\n",
    "    \"59\" : \"MD\",\n",
    "    \"60\" : \"WD\",\n",
    "    \"61\" : \"XD\"\n",
    "}\n",
    "\n",
    "def fetch_options_url(discipline, cat_id, headers):\n",
    "    url = f\"https://bwfworldtour.bwfbadminton.com/rankings/?id=9&cat_id={cat_id}&ryear=2018&week=3&page_size=100&page_no=1\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    \n",
    "    ranking_select = soup.find('select', id='ranking-week')\n",
    "    urls = []\n",
    "    if ranking_select:\n",
    "        for option in ranking_select.find_all('option'):\n",
    "            value = option['value']\n",
    "            year, week = value.split('--')\n",
    "            new_url = f\"{url}&ryear={year}&week={week}&page_size=100&page_no=1\"\n",
    "            urls.append(new_url)\n",
    "    \n",
    "    return discipline, urls\n",
    "\n",
    "def process_url(discipline, url, headers):\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = bs(r.content, 'html.parser')\n",
    "    \n",
    "    rank_data = {\n",
    "        \"Rank\": [],\n",
    "        \"Country/Territory\": [],\n",
    "        \"Name\": [],\n",
    "        \"Date\": [],\n",
    "        \"Points Accumulated\": []\n",
    "    }\n",
    "    \n",
    "    date_option = soup.find('select', {'id': 'ranking-week'}).find('option', {'selected': 'selected'})\n",
    "    date_text = date_option.text.strip()\n",
    "    date = date_text.split('(')[1].split(')')[0]  # Extract date within brackets\n",
    "    \n",
    "    table = soup.find('table')\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        if not row.get('class') or 'row-even' in row.get('class'):\n",
    "            cols = row.find_all('td')\n",
    "            rank_data[\"Rank\"].append(cols[0].text.strip())\n",
    "            rank_data[\"Country/Territory\"].append(cols[1].find('span').text.strip())\n",
    "            rank_data[\"Name\"].append(cols[2].find('a').text.strip())\n",
    "            rank_data[\"Date\"].append(date)\n",
    "            rank_data[\"Points Accumulated\"].append(cols[4].text.strip())\n",
    "    \n",
    "    return discipline, rank_data\n",
    "\n",
    "def main(discipline_ids, headers):\n",
    "    rankings_urls = {}\n",
    "    rank_data = {discipline: {\"Rank\": [], \"Country/Territory\": [], \"Name\": [], \"Date\": [], \"Points Accumulated\": []} for discipline in discipline_ids.values()}\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(fetch_options_url, discipline, cat_id, headers) for cat_id, discipline in discipline_ids.items()]\n",
    "        for future in as_completed(futures):\n",
    "            discipline, urls = future.result()\n",
    "            rankings_urls[discipline] = urls\n",
    "        \n",
    "        futures = [executor.submit(process_url, discipline, url, headers) for discipline, urls in rankings_urls.items() for url in urls]\n",
    "        for future in as_completed(futures):\n",
    "            discipline, data = future.result()\n",
    "            rank_data[discipline][\"Rank\"].extend(data[\"Rank\"])\n",
    "            rank_data[discipline][\"Country/Territory\"].extend(data[\"Country/Territory\"])\n",
    "            rank_data[discipline][\"Name\"].extend(data[\"Name\"])\n",
    "            rank_data[discipline][\"Date\"].extend(data[\"Date\"])\n",
    "            rank_data[discipline][\"Points Accumulated\"].extend(data[\"Points Accumulated\"])\n",
    "\n",
    "    return rank_data\n",
    "\n",
    "rank_data = main(discipline_ids, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3807c024-eefc-4abd-8ee2-63ecaeada07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "# Create a DataFrame for each discipline\n",
    "for discipline in rank_data.keys():\n",
    "    # Create DataFrame for the current discipline\n",
    "    df = pd.DataFrame(rank_data[discipline])\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[discipline] = df\n",
    "WS_rank = dataframes['WS']\n",
    "WS_rank[\"Name\"] = WS_rank[\"Name\"].str.title()\n",
    "MS_rank = dataframes['MS']\n",
    "MS_rank[\"Name\"] = MS_rank[\"Name\"].str.title()\n",
    "WD_rank = dataframes['WD']\n",
    "WD_rank[\"Name\"] = WD_rank[\"Name\"].str.title()\n",
    "MD_rank = dataframes['MD']\n",
    "MD_rank[\"Name\"] = MD_rank[\"Name\"].str.title()\n",
    "XD_rank = dataframes['XD']\n",
    "XD_rank[\"Name\"] = XD_rank[\"Name\"].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9b089b2-f332-440c-bab4-d7a54c5abf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrames as CSV\n",
    "WS_rank.to_csv('CSV Files/WS_rank.csv', index=False)\n",
    "MS_rank.to_csv('CSV Files/MS_rank.csv', index=False)\n",
    "WD_rank.to_csv('CSV Files/WD_rank.csv', index=False)\n",
    "MD_rank.to_csv('CSV Files/MD_rank.csv', index=False)\n",
    "XD_rank.to_csv('CSV Files/XD_rank.csv', index=False)\n",
    "\n",
    "data_df.to_csv('CSV Files/data_df.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
